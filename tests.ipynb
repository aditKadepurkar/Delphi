{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Delphi/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import Datasets\n",
    "import chromadb\n",
    "from chromadb import Collection\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer, models, losses, util, InputExample, evaluation, SentenceTransformerTrainingArguments, SentenceTransformerTrainer\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import json\n",
    "# from langchain.text_splitter import NLTKTextSplitter\n",
    "# from langchain_community.document_loaders import (\n",
    "#     # PDFLoader,\n",
    "#     # WordDocumentLoader,\n",
    "#     TextLoader,\n",
    "#     # ExcelLoader,\n",
    "#     CSVLoader,\n",
    "#     # PowerPointLoader\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingList(model, sentences):\n",
    "  \"\"\" This function returns the sentence embeddings for a given document using the SentenceTransformer model and encapsulates them inside a list.\n",
    "\n",
    "  @param model: SentenceTransformer: The model to be used for getting the embeddings.\n",
    "  @param sentences: list: The list of sentences for which embeddings are to be calculated. \"\"\"\n",
    "\n",
    "  embeddings = model.encode(sentences)\n",
    "  return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel() -> SentenceTransformer:\n",
    "  \"\"\" This function creates a SentenceTransformer model using the 'sentence-transformers/all-MiniLM-L6-v2' base model. It utilizes accelerator to make use of multiple GPUs\n",
    "  and adds a layer to get the sentence embeddings via mean pooling. This model will be used for training sbert's sentence embeddings. \"\"\"\n",
    "\n",
    "  accelerator = Accelerator()\n",
    "  print(f\"Using GPUs: {accelerator.num_processes}\")\n",
    "\n",
    "  # Get the base model to train\n",
    "  word_embedding_model = models.Transformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "  # Add layer to get \"sentence embedding\" (using mean pooling)\n",
    "  pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "  model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An initial list of actions that the AI can choose between\n",
    "SET_OF_ACTIONS = ['new file', 'search web', 'search files', 'resize window', 'choose option', 'open file', 'close file', 'minimize window', 'maximize window', 'scroll up', 'scroll down', 'scroll left', 'scroll right', 'open', 'close', 'upload']\n",
    "# SET_OF_ACTIONS = ['new file', 'search', 'resize window', 'choose option', 'scroll', 'open file', 'close file', 'minimize window', 'maximize window', 'scroll up', 'scroll down', 'scroll left', 'scroll right', 'copy', 'paste', 'cut', 'undo', 'redo', 'drag and drop', 'select', 'deselect', 'save', 'save as', 'open', 'close', 'upload']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic file gathering and putting into database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(initdir: str, file_extensions: list):\n",
    "    '''\n",
    "    Returns a list of file under initdir and all its subdirectories\n",
    "    that have file extension contained in file_extensions.\n",
    "    ''' \n",
    "    file_list = []\n",
    "    file_count = {key: 0 for key in file_extensions}  # for reporting only\n",
    "    \n",
    "    # Traverse through directories to find files with specified extensions\n",
    "    for root, _, files in os.walk(initdir):\n",
    "        for file in files:\n",
    "            ext = file.split('.')[-1].lower()\n",
    "            if ext in file_extensions:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_list.append(file_path)\n",
    "                # increment type of file\n",
    "                file_count[ext] += 1\n",
    "    \n",
    "    # total = len(file_list)\n",
    "    # print(f'There are {total} files under dir {initdir}.')\n",
    "    # for k, n in file_count.items():\n",
    "        # print(f'   {n} : \".{k}\" files')\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/resolutions.txt',\n",
       " 'test/sorting.py',\n",
       " 'test/random.py',\n",
       " 'test/example.txt',\n",
       " 'test/buhao.c']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files('test', ['txt', 'c', 'py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_info(file_path: str):\n",
    "    '''\n",
    "    Open the file at the given file path and return its content.\n",
    "    \n",
    "    @param file_path: str: The path of the file to be opened.\n",
    "    @return: str: The content of the file.\n",
    "    '''\n",
    "    try: \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        # metadata = file.metadata\n",
    "        file_name = file_path\n",
    "        return (file_name, content)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test/resolutions.txt',\n",
       " '1. Exercise regularly and stay fit.\\n2. Learn a new programming language.\\n3. Read at least one book every month.\\n4. Spend more time with family and friends.\\n5. Travel to at least two new places.\\n6. Save money and stick to a budget.\\n7. Volunteer for a good cause.\\n8. Improve my communication skills.\\n9. Learn a musical instrument.\\n10. Practice mindfulness and reduce stress.')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_document_info('test/resolutions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ollama implementation for better semantics(you need an ollama server running in the background for this to work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelfile = '''\n",
    "FROM llama3\n",
    "SYSTEM You have to give a clear and detailed and accurate description of the file contents and NOTHING else.\n",
    "'''\n",
    "\n",
    "ollama.create(model='example', modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'example',\n",
       " 'created_at': '2024-07-31T16:44:48.64024Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': '**Text File Contents:**\\n\\n1. Exercise regularly and stay fit.\\n2. Learn a new programming language.\\n3. Read at least one book every month.\\n4. Spend more time with family and friends.\\n5. Travel to at least two new places.\\n6. Save money and stick to a budget.\\n7. Volunteer for a good cause.\\n8. Improve my communication skills.\\n9. Learn a musical instrument.\\n10. Practice mindfulness and reduce stress.\\n\\n**File Type:** Text File (UTF-8 encoded)\\n\\n**Size:** 276 bytes\\n\\n**Last Modified:** Not available\\n\\n**Checksum:** Not available'},\n",
       " 'done': True,\n",
       " 'total_duration': 22521467334,\n",
       " 'load_duration': 14137200500,\n",
       " 'prompt_eval_count': 130,\n",
       " 'prompt_eval_duration': 1196688000,\n",
       " 'eval_count': 124,\n",
       " 'eval_duration': 7174357000}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.chat(model=\"example\", messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': f'{get_document_info('test/resolutions.txt')[1]}'\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_description(file_path: str, modelfile: str):\n",
    "    \"\"\"\n",
    "    Get the description of the input from the Ollama model.\n",
    "    \n",
    "    @param file_path: str: The file with the document.\n",
    "    @param modelfile: str: The modelfile for the Ollama model.\n",
    "    @return: str: The description of the input.\n",
    "    \"\"\"\n",
    "    content = get_document_info(file_path)\n",
    "    # print(content)\n",
    "    ollama.create(model='example', modelfile=modelfile)\n",
    "    response = ollama.chat(model=\"example\", messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'Filename: {os.path.basename(content[0])}, File content:{content[1]}'\n",
    "        }])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A C program that takes two integers as input from the user and compares them to determine if one is greater than, less than, or equal to the other.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ollama_description('test/buhao.c', modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "embedmodel = getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "doc_collection = client.get_or_create_collection(\"docs2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_database(file_list: list, collection: Collection, embedmodel: SentenceTransformer, modelfile: str):\n",
    "    # sentences = []\n",
    "    # for file in file_list:\n",
    "    #     get_ollama_description(file_path=file, modelfile=modelfile)\n",
    "    \n",
    "    sentences = []\n",
    "    for file in file_list:\n",
    "        sentences.append(get_ollama_description(file_path=file, modelfile=modelfile))\n",
    "    # print(sentences)\n",
    "    embeds = getEmbeddingList(model=embedmodel, sentences=sentences)\n",
    "    collection.add(\n",
    "        embeddings=embeds,\n",
    "        documents=file_list,\n",
    "        ids=[f'id{i}' for i in range(len(file_list))],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_database(file_list=list_files('test', ['txt', 'c', 'py']), collection=doc_collection, embedmodel=embedmodel, modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune this or look at online examples because current outputs are bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/random.py\n"
     ]
    }
   ],
   "source": [
    "# bad\n",
    "input = \"Python codes for web scraping\"\n",
    "\n",
    "query_result = doc_collection.query(\n",
    "            query_embeddings=[getEmbeddingList(embedmodel, input)],\n",
    "            n_results=1,\n",
    "        )\n",
    "\n",
    "print(query_result['documents'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id0', 'id3', 'id2', 'id1', 'id4']], 'distances': [[30.731735229492188, 48.405677795410156, 54.165950775146484, 57.87548065185547, 58.31592559814453]], 'metadatas': [[None, None, None, None, None]], 'embeddings': None, 'documents': [['test/resolutions.txt', 'test/example.txt', 'test/random.py', 'test/sorting.py', 'test/buhao.c']], 'uris': None, 'data': None, 'included': ['metadatas', 'documents', 'distances']}\n"
     ]
    }
   ],
   "source": [
    "# bad\n",
    "input = \"new years resolutions\"\n",
    "\n",
    "query_result = doc_collection.query(\n",
    "            query_embeddings=[getEmbeddingList(embedmodel, input)],\n",
    "            n_results=5,\n",
    "        )\n",
    "\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(file_path: str, content: str):\n",
    "    '''\n",
    "    Create a file at the given file path with the given content.\n",
    "    \n",
    "    @param file_path: str: The path of the file to be created.\n",
    "    @param content: str: The content of the file.\n",
    "    '''\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_path: str):\n",
    "    '''\n",
    "    Remove the file at the given file path.\n",
    "    \n",
    "    @param file_path: str: The path of the file to be removed.\n",
    "    '''\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_files(query: str, collection: Collection, embedmodel: SentenceTransformer):\n",
    "    '''\n",
    "    Search for files in the collection that match the query.\n",
    "    \n",
    "    @param query: str: The query to search for.\n",
    "    @param collection: Collection: The collection to search in.\n",
    "    @param embedmodel: SentenceTransformer: The model to be used for getting the embeddings.\n",
    "    @return: list: The list of files that match the query.\n",
    "    '''\n",
    "    query_result = collection.query(\n",
    "        query_embeddings=[getEmbeddingList(embedmodel, query)],\n",
    "        n_results=1,\n",
    "    )\n",
    "    return query_result['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path: str):\n",
    "    '''\n",
    "    Open the file at the given file path.\n",
    "    \n",
    "    @param file_path: str: The path of the file to be opened.\n",
    "    '''\n",
    "    os.system(f'open {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file('test/random.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing input to open file:\n",
    "\n",
    "input = \"open my new years resolutions\"\n",
    "\n",
    "query_result = doc_collection.query(\n",
    "            query_embeddings=[getEmbeddingList(embedmodel, input)],\n",
    "            n_results=1,\n",
    "        )\n",
    "\n",
    "\n",
    "open_file(query_result['documents'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function calling using GPT-4o-mini\n",
    "\n",
    "messages = [{'role': 'user', 'content': \"open my new years resolutions\"}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"open_file\",\n",
    "            \"description\": \"Open the file at the given file path.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"file_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The path of the file to be opened.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"file_path\"],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_files\",\n",
    "            \"description\": \"Search for the file that is most similar to the query and return the file path.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query to search for the file. This query should be something that is semantically similar to what we are looking for.\",\n",
    "                    },\n",
    "                    \"collection\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The collection to search in. (Use doccollection for now)\"\n",
    "                    },\n",
    "                    \"embedmodel\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The model to be used for getting the embeddings. (Use embedmodel for now)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    "    \n",
    ")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/resolutions.txt\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "available_functions = {\n",
    "    \"open_file\": open_file,\n",
    "    \"search_files\": search_files,\n",
    "}\n",
    "\n",
    "if tool_calls:\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        function_response = function_to_call(\n",
    "            query=function_args.get(\"query\"),\n",
    "            collection=doc_collection,\n",
    "            embedmodel=embedmodel\n",
    "        )\n",
    "        \n",
    "        # print(function_response)\n",
    "        \n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "        message = messages\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "\n",
    "response_message = second_response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        function_response = function_to_call(\n",
    "            file_path=function_args.get(\"file_path\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to get a vocal dataset from hf to do tests\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Delphi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
